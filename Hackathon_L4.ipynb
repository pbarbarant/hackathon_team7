{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon_L4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Code équipe L4 (groupe 7+11) sur le sujet 2"
      ],
      "metadata": {
        "id": "SgPFvft3FzIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements"
      ],
      "metadata": {
        "id": "GzWR1E42GDD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC0MifMpFtRe",
        "outputId": "75f785a0-e122-4a7b-a7ee-68016b15f6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     / 13.6 MB 350 kB/s\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 437 kB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 582 kB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 52.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 408 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 42.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 308 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 113 kB 48.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-audiomentations (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 408 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 546 kB 44.1 MB/s \n",
            "\u001b[?25h  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.25.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 35.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.24.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.24.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed tensorflow-io-0.25.0 tensorflow-io-gcs-filesystem-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q https://github.com/pyannote/pyannote-audio/archive/develop.zip\n",
        "!pip install -q speechbrain\n",
        "!pip install pydub\n",
        "!pip install tensorflow_io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_hub as hub\n",
        "from IPython import display\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "from pyannote.audio import Pipeline\n",
        "import librosa  # just to demo, not necessary, as you already have the data\n",
        "import soundfile\n",
        "from pydub import AudioSegment as am\n",
        "from pyannote.audio.pipelines import SpeakerDiarization \n",
        "\n",
        "\n",
        "## for pre-processing\n",
        "!apt install ffmpeg\n",
        "!pip install spleeter\n",
        "import os \n",
        "\n",
        "#Not necessary\n",
        "from scipy.io import wavfile\n",
        "import scipy\n",
        "from pyannote.core import notebook, Timeline\n"
      ],
      "metadata": {
        "id": "Co07hI5xGTWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae7004e-c8de-4bc9-a6c2-2324e3cfca71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Collecting spleeter\n",
            "  Downloading spleeter-2.3.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting httpx[http2]<0.20.0,>=0.19.0\n",
            "  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting numpy<1.20.0,>=1.16.0\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 47.2 MB/s \n",
            "\u001b[?25hCollecting norbert==0.2.1\n",
            "  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████    | 397.4 MB 43.8 MB/s eta 0:00:02"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting Data"
      ],
      "metadata": {
        "id": "c79J0C_eZB0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GMoCymRcZKkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Input/ /content/input/"
      ],
      "metadata": {
        "id": "-P3_Z3POZIAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/men_and_women_yamnet/ /content/men_and_women_yamnet/"
      ],
      "metadata": {
        "id": "FZNmdTjOcV0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions and variables"
      ],
      "metadata": {
        "id": "YnMM-owzZpfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitWavAudioMubin():\n",
        "    def __init__(self, folder, filename):\n",
        "        self.folder = folder\n",
        "        self.filename = filename\n",
        "        self.filepath = os.path.join(folder, filename)\n",
        "        \n",
        "        self.audio = AudioSegment.from_wav(self.filepath)\n",
        "    \n",
        "    def get_duration(self):\n",
        "        return self.audio.duration_seconds\n",
        "    \n",
        "    def single_split(self, from_sec, to_sec, split_filename):\n",
        "        t1 = from_sec * 1000\n",
        "        t2 = to_sec * 1000\n",
        "        split_audio = self.audio[t1:t2]\n",
        "        split_audio.export(os.path.join(self.folder, split_filename), format=\"wav\")\n",
        "        \n",
        "    def multiple_split(self, sec_per_split=2):\n",
        "        total_secs = math.ceil(self.get_duration())\n",
        "        for i in range(0, total_secs, 2):\n",
        "            split_fn = str(i) + '_' + self.filename\n",
        "            self.single_split(i, i+sec_per_split, split_fn)\n",
        "            print(str(i) + ' Done')\n",
        "            if i == total_secs - sec_per_split:\n",
        "                print('All splited successfully')"
      ],
      "metadata": {
        "id": "PHdL1SBsGy-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_16k(path):\n",
        "    '''Convertit le fichier en audio 16000Hz\n",
        "    et 16-bits'''\n",
        "    sound = am.from_file(path, format='wav')\n",
        "    sound = sound.set_frame_rate(16000)\n",
        "    sound.export('cache_temp/temp_file.wav' , format='wav')\n",
        "    y, sr = librosa.load(path, sr=16000)\n",
        "    # write to a new wave file with sample rate sr and format 'signed 16bit'\n",
        "    soundfile.write(path, y, 16000, subtype='PCM_16')\n",
        "    os.remove('cache_temp/temp_file.wav')"
      ],
      "metadata": {
        "id": "l4pwtLqkaqjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor.\"\"\"\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    wav, sample_rate = tf.audio.decode_wav(\n",
        "          file_contents,\n",
        "          desired_channels=1)\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ],
      "metadata": {
        "id": "7B2zsmbmawPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = './men_and_women_yamnet'\n",
        "\n",
        "reloaded_model = tf.saved_model.load(saved_model_path)\n",
        "classes = ['m', 'f']\n",
        "cwd = os.path.abspath('')"
      ],
      "metadata": {
        "id": "p9uiHCMrXWxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_speakers(file):\n",
        "  own_file = file\n",
        "  OWN_FILE = {'audio': own_file}\n",
        "  notebook.reset()\n",
        "  \n",
        "  pipeline = SpeakerDiarization()\n",
        "  initial_params = {\"onset\":0.60, \"offset\":0.481,\"min_duration_on\":0.0055,\"min_duration_off\":0.098, \"min_activity\":2.078, \"stitch_threshold\": 0.40, \"clustering\": {\"method\": \"average\", \"threshold\": 0.1}, }\n",
        "  pipeline.instantiate(initial_params)\n",
        "  \n",
        "  os.system('spleeter separate -o inter/ -f \"{instrument}/{filename}.{codec}\" '+ file)\n",
        "  dia = pipeline('/content/inter/'+file[16::])\n",
        "  \n",
        "  speakers = dia.labels()\n",
        "  resu = []\n",
        "  filemalecount = 0\n",
        "  filefemalecount = 0\n",
        "  for i,speaker in enumerate(speakers):\n",
        "    pre = dia.label_timeline(speaker)\n",
        "    timel = Timeline()\n",
        "    folder = os.path.join(os.path.join(cwd, \"output\"), \"speaker_\" + str(i))\n",
        "    is_speaker_male_likelihood = 0\n",
        "    is_speaker_female_likelihood = 0\n",
        "    try:\n",
        "      os.mkdir(folder)\n",
        "    except:\n",
        "      pass\n",
        "    split_wav = SplitWavAudioMubin(folder, file)\n",
        "    export_filename = os.path.basename(file)\n",
        "    for segment in pre:\n",
        "      if segment.duration >= 2.0:\n",
        "        start = segment.start\n",
        "        end = segment.end\n",
        "        is_segment_male_likelihood = 0\n",
        "        is_segment_female_likelihood = 0\n",
        "        for i, t in enumerate(np.arange(start, end, 2)):\n",
        "              split_fn = str(i) + '_' + export_filename\n",
        "              if i+2 <= end:\n",
        "                split_wav.single_split(t, t+2, split_fn)\n",
        "                path_to_analyze = folder + '/' + split_fn\n",
        "                convert_to_16k(path_to_analyze)\n",
        "                testing_wav_data = load_wav_16k_mono(path_to_analyze) # Il faut mettre une donnee en 16000Hz\n",
        "                reloaded_results = reloaded_model(testing_wav_data)\n",
        "                men_or_women = classes[tf.argmax(reloaded_results)]\n",
        "                if men_or_women == 'm':\n",
        "                  is_segment_male_likelihood +=1\n",
        "                else:\n",
        "                  is_segment_female_likelihood += 1      \n",
        "        if is_segment_male_likelihood > is_segment_female_likelihood:\n",
        "          filemalecount +=1\n",
        "        else: \n",
        "          filefemalecount +=1\n",
        "  return {'M' : filemalecount, 'F' : filefemalecount}"
      ],
      "metadata": {
        "id": "9VEK0lCCKW4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code execution"
      ],
      "metadata": {
        "id": "qsSqXqAxaPWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-41ASk9kl1eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filelist = [file for file in os.listdir('/content/input/')]\n",
        "filelistabs = ['/content/input/' + file for file in filelist if file.endswith(\".wav\")]\n",
        "df_to_concat = []\n",
        "for i, file in enumerate(filelistabs):\n",
        "  dic = count_speakers(file)\n",
        "  print(file + \" :\")\n",
        "  print(dic)\n",
        "  ##df = df_dic(dic,file)\n",
        "  ##df_to_concat.append(df)\n",
        "##df_results = pd.concat(df_to_concat, axis=1)\n",
        "##df_results.to_csv(\"results.csv\")\n"
      ],
      "metadata": {
        "id": "xFfLan-JVYkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}